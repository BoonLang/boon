## Chapter 2.4: Event Loop

### 2.4.1 Central Scheduler

Replace `Task::start_droppable` with explicit event loop. **Canonical EventLoop definition** (combines all fields):

```rust
pub struct EventLoop {
    // Core state
    arena: Arena,
    timer_queue: BinaryHeap<TimerEvent>,
    dirty_nodes: Vec<DirtyEntry>,  // (SlotId + Port) for multi-input nodes
    dom_events: VecDeque<DomEvent>,

    // Tick tracking
    current_tick: u64,
    tick_seq: u64,           // Sequence within tick for ordering

    // Wall-clock integration (see Issue 6)
    tick_start_ms: f64,      // Performance.now() when tick started
    ms_per_tick: f64,        // Default: 16.67 (60 fps)

    // Scope cleanup (see Section 4.4)
    pending_finalizations: Vec<ScopeId>,

    // Effects - FIFO order for determinism (see §2.4.7)
    pending_effects: Vec<NodeEffect>,

    // Scheduling (used in §2.4.12)
    // Browser: prevents duplicate queueMicrotask calls
    // CLI: prevents reentrancy when schedule_microtask runs synchronously (see §3.3.6)
    tick_scheduled: AtomicBool,
}
```

**NOTE:** No `run_until_idle()` - browser kills page if main thread blocks (see Issue 28). Use `run_tick()` instead.

**DirtyEntry carries port for multi-input nodes:**
```rust
#[derive(Clone, Copy)]
pub struct DirtyEntry {
    pub slot: SlotId,
    pub port: Port,  // Which input triggered this dirty mark
}
```

**Why port is needed:** Multi-input nodes (LATEST, Router field updates) need to know which input changed for deterministic sorting. Sorting by `(source_id, scope_id, port)` requires port information. Without it, two dirty marks on the same node (different ports) would be indistinguishable.

### 2.4.2 Logical Ticks (Deterministic Ordering)

See **Issue 20** for full tick processing algorithm with quiescence loop.

```rust
impl EventLoop {
    pub fn run_tick(&mut self) {
        self.current_tick += 1;
        self.tick_seq = 0;

        // 1. Collect external inputs
        self.process_timers();
        self.process_dom_events();

        // 2. Propagate until quiescence (see Issue 20 for full algorithm)
        while !self.dirty_nodes.is_empty() {
            // Sort for determinism, process, may add new dirty nodes
            // ...
        }

        // 3. Finalize scopes at tick end
        self.finalize_pending_scopes();

        // 4. Execute effects (after all nodes settled)
        self.execute_pending_effects();
    }
}
```

**Determinism guarantees:**
- Same input events → same output sequence
- Sort key: `(source_id, scope_id, port)` for deterministic processing order
- `tick_seq` is a monotonic counter (for debugging/timestamps), NOT part of sort
- Glitch-free: within tick, use last-value semantics

### 2.4.3 Backpressure (Deadlock Prevention)

**Rule:** No node ever blocks. If output queue full, return "not ready".

```rust
pub enum ProcessResult {
    Emitted(Message),
    NotReady,  // Output queue full, retry later
    NoOutput,  // Node consumed input but produced nothing
}

impl EventLoop {
    fn process_node(&mut self, node: SlotId) -> ProcessResult {
        let node = self.arena.get_mut(node);

        // Check if output channel has capacity
        if !node.output_has_capacity() {
            return ProcessResult::NotReady;  // Will retry next tick
        }

        // Process normally
        node.process()
    }
}
```

**Backpressure policies by source type:**
| Source | Policy |
|--------|--------|
| Timer | Drop if full (timer keeps ticking) |
| Mouse move | Coalesce (keep latest position) |
| Click/keypress | Buffer (don't drop user input) |
| Network | Buffer with timeout |

### 2.4.4 Explicit Scope Finalization

**Problem:** Implicit drops cause "receiver is gone" errors.

**Solution:** Scopes are explicitly finalized, not implicitly dropped.

```rust
pub enum ScopeState {
    Active,
    Finalizing,  // Cleanup in progress
    Finalized,   // Ready for deallocation
}

impl Bus {
    fn remove_item(&mut self, key: ItemKey) {
        let scope = self.item_scopes.get_mut(key);

        // 1. Mark as finalizing (no new messages accepted)
        scope.state = ScopeState::Finalizing;

        // 2. Emit cleanup event (subscribers can react)
        self.emit(ListDelta::Remove { key });

        // 3. Schedule finalization for next epoch
        self.event_loop.schedule_finalization(scope.id);
    }
}
```

**Epoch-based deallocation:**
```rust
impl EventLoop {
    fn end_tick(&mut self) {
        // After tick completes, finalize scheduled scopes
        for scope_id in self.pending_finalizations.drain(..) {
            self.finalize_scope(scope_id);
        }
    }

    fn finalize_scope(&mut self, scope_id: ScopeId) {
        // All nodes in scope can now be safely freed
        for slot in self.arena.nodes_in_scope(scope_id) {
            self.arena.free(slot);
        }
    }
}
```

**Benefits:**
- No "receiver is gone" errors mid-processing
- Cleanup is deterministic and debuggable
- Items can emit final events before deallocation
- Safe for multi-threaded execution

### 2.4.4.1 WHILE Arm Finalization Timing

**Rule:** WHILE arm switching happens at **tick end**, not during tick processing.

When a WHILE node receives input that changes which arm is active:

1. **During tick:** WHILE node detects arm change, queues finalization of old arm
2. **During tick:** Messages continue flowing through OLD arm (for consistency)
3. **At tick end:** `finalize_pending_scopes()` removes old arm's routes
4. **At tick end:** New arm is activated (routes already exist from compilation)
5. **Next tick:** Messages flow through NEW arm

```rust
impl EventLoop {
    fn process_while_node(&mut self, while_slot: SlotId, input: Payload) {
        let while_node = self.arena.get_mut(while_slot)?;
        let NodeKind::SwitchedWire { current_arm, arm_outputs, pattern } = &mut while_node.kind else { return };

        // Evaluate pattern to determine new arm
        let new_arm = self.match_pattern(pattern, &input);

        if Some(new_arm) != *current_arm {
            // OLD arm continues for rest of this tick (for consistency)
            // Queue old arm for finalization at tick end
            if let Some(old_arm) = *current_arm {
                let old_scope = self.get_arm_scope(while_slot, old_arm);
                self.pending_finalizations.push(old_scope);
            }

            // Mark that switch will happen at tick end
            self.pending_arm_switches.push((while_slot, new_arm));
        }

        // Forward value through CURRENT arm (even if switching)
        if let Some(arm) = *current_arm {
            self.forward_to_arm(arm_outputs[arm], input);
        }
    }

    fn finalize_pending_scopes(&mut self) {
        // 1. Finalize old WHILE arms (removes routes, frees nodes)
        for scope_id in self.pending_finalizations.drain(..) {
            self.finalize_scope(scope_id);
        }

        // 2. Activate new WHILE arms (routes already exist)
        for (while_slot, new_arm) in self.pending_arm_switches.drain(..) {
            let while_node = self.arena.get_mut(while_slot)?;
            if let NodeKind::SwitchedWire { current_arm, arm_outputs, .. } = &mut while_node.kind {
                *current_arm = Some(new_arm);
                // Mark new arm output as dirty for next tick
                self.mark_dirty(arm_outputs[new_arm], Port::Output);
            }
        }
    }
}
```

**Order of operations at tick end:**
1. Old arm routes are removed FIRST (via `finalize_scope`)
2. New arm is activated SECOND (sets `current_arm`)
3. New arm output is marked dirty for NEXT tick

**Why tick-end switching:**
- Messages in-flight during current tick see consistent routing
- No "message sent to finalized scope" errors
- Pattern evaluation is deterministic (happens once per tick)
- Easy to debug: arm changes are visible as discrete events between ticks

### 2.4.5 Timer Implementation

No `async Timer::sleep()`. See **Issue 6** for wall-clock integration and **Issue 30** for backgrounded tab handling.

```rust
// Canonical TimerEvent (from Issue 6) - uses BOTH tick and wall-clock
struct TimerEvent {
    deadline_tick: u64,    // For deterministic ordering
    deadline_ms: f64,      // For precise wall-clock timing
    node_id: SlotId,
}
```

**WASM integration:** Use microtasks for reactive propagation (see §2.4.12).

### 2.4.6 Full Tick Processing (Quiescence Loop)

Complete propagation algorithm:

```rust
impl EventLoop {
    pub fn run_tick(&mut self) {
        self.current_tick += 1;
        self.tick_seq = 0;

        // 1. Collect external inputs
        self.process_timers();
        self.process_dom_events();

        // 2. Propagate until quiescence (no more dirty nodes)
        while !self.dirty_nodes.is_empty() {
            // Sort for determinism: (source_id, scope_id, port)
            // Uses arena.get_address() side table (see §2.2.6)
            self.dirty_nodes.sort_by_key(|entry| {
                let addr = self.arena.get_address(entry.slot).expect("valid slot");
                (addr.source_id, addr.scope_id, entry.port)
            });

            // Process all dirty nodes for this "wave"
            let to_process: Vec<_> = self.dirty_nodes.drain(..).collect();

            for entry in to_process {
                self.tick_seq += 1;
                let new_dirty = self.process_node(entry.slot, entry.port);
                self.dirty_nodes.extend(new_dirty);  // May add subscribers
            }
        }

        // 3. Finalize scopes at tick end
        self.finalize_pending_scopes();

        // 4. Execute effects (after all nodes settled)
        self.execute_pending_effects();
    }
}
```

**Glitch-freedom:** Within a tick, nodes see latest values because we iterate until quiescence.

### 2.4.7 Effect Node Model

Side effects (console.log, navigation, localStorage) are handled via effect nodes:

```rust
pub enum NodeEffect {
    None,
    ConsoleLog { level: LogLevel, message: String },
    RouterNavigate { url: String },
    LocalStorageSet { key: String, value: String },
    // ... other effects
}

pub struct EffectNode {
    pub effect_kind: EffectKind,
    pub trigger_input: SlotId,
    pub last_execution_tick: u64,  // Prevent double-run on restore
}

impl EffectNode {
    fn process(&mut self, msg: Message, current_tick: u64) -> Option<NodeEffect> {
        // Idempotency: don't re-run effects for same tick
        if current_tick <= self.last_execution_tick {
            return None;
        }
        self.last_execution_tick = current_tick;

        // Generate effect (executed by EventLoop after tick)
        Some(self.create_effect(&msg))
    }
}
```

**Restore safety:** On snapshot restore, set `last_execution_tick` to restored tick to prevent re-running effects.

**Execution order:** Effects are executed in **FIFO order** - the order they were queued during propagation. This ensures:
- Determinism (same input → same effect sequence)
- Intuitive behavior (effects happen in code order)
- Optimal performance (Vec push/drain, cache-friendly)

#### Effect Nesting Semantics

Effects are **collected during tick processing, not executed inline**. This applies even when effect-producing nodes are nested:

```boon
// Nested effect example
result |> THEN {
    Log/info(message: TEXT { Outer: {result} })
    inner_value |> THEN {
        Log/info(message: TEXT { Inner: {inner_value} })
    }
}
```

**Processing order:**

1. During tick, nodes are processed in topological order
2. When a node produces an effect, it's **queued** in `pending_effects`
3. Nested THEN bodies that produce effects add to the **same queue**
4. All effects execute **after full quiescence** (no more dirty nodes)

```rust
impl EventLoop {
    fn process_node(&mut self, slot: SlotId, port: Port) -> Vec<DirtyEntry> {
        let node = self.arena.get_mut(slot);

        // Node may produce an effect
        if let Some(effect) = node.process(port) {
            // Queue it, don't execute inline
            self.pending_effects.push(effect);
        }

        // ... mark subscribers dirty
    }

    fn execute_pending_effects(&mut self) {
        // FIFO order - effects execute in the order they were queued
        for effect in self.pending_effects.drain(..) {
            self.execute_effect(effect);
        }
    }
}
```

**Why not inline execution:**

| Approach | Problem |
|----------|---------|
| Execute effects inline | Effects may see inconsistent state (mid-propagation) |
| Queue and execute after | All effects see final tick state |

**Effect chains example:**

```boon
a: 1
b: a + 1
c: b + 1

// These all log in FIFO order after propagation completes
a |> THEN { Log/info(message: TEXT { a = {a} }) }
b |> THEN { Log/info(message: TEXT { b = {b} }) }
c |> THEN { Log/info(message: TEXT { c = {c} }) }

// Output (in order):
// a = 1
// b = 2
// c = 3
```

**Determinism guarantee:** Same input events → same effect order (FIFO by queue time during propagation, which is deterministic due to topological sort).

### 2.4.8 Effect Restore Validation

What if external state changed during session (user logged out, network unavailable)?

```rust
impl EffectNode {
    fn process_on_restore(&mut self, current_tick: u64) -> EffectResult {
        if current_tick <= self.last_execution_tick {
            return EffectResult::Skip;
        }

        if self.requires_validation {
            match self.validate_preconditions() {
                Ok(()) => {}
                Err(ValidationError::UserLoggedOut) => {
                    return EffectResult::SkipWithWarning("User logged out during session");
                }
                Err(ValidationError::NetworkUnavailable) => {
                    return EffectResult::QueueForRetry;
                }
            }
        }

        self.last_execution_tick = current_tick;
        EffectResult::Execute(self.create_effect())
    }
}

pub enum EffectResult {
    Execute(NodeEffect),
    Skip,
    SkipWithWarning(&'static str),
    QueueForRetry,
}
```

**Effect categories:**
| Effect Type | On Restore | Validation |
|-------------|------------|------------|
| ConsoleLog | Skip (already logged) | None |
| RouterNavigate | Re-execute (URL may differ) | Check if route exists |
| LocalStorageSet | Skip (already set) | None |
| NetworkRequest | Skip or retry | Check network available |
| DOMManipulation | Re-execute (DOM rebuilt) | Check element exists |

### 2.4.9 Stream/pulses Sequential Semantics

`Stream/pulses(n)` emits N values across N ticks (matches FPGA clock semantics):

```rust
pub struct PulsesNode {
    remaining: u32,
    total: u32,
}

impl PulsesNode {
    fn on_input(&mut self, count: u32, event_loop: &mut EventLoop) {
        self.total = count;
        self.remaining = count;
        if self.remaining > 0 {
            event_loop.schedule_next_tick(self.slot_id);
        }
    }

    fn on_tick(&mut self, event_loop: &mut EventLoop) -> Option<Message> {
        if self.remaining > 0 {
            let pulse_index = self.total - self.remaining;
            self.remaining -= 1;

            if self.remaining > 0 {
                event_loop.schedule_next_tick(self.slot_id);
            }

            Some(Message::new(pulse_index))
        } else {
            None
        }
    }
}
```

**Why sequential (not batched):**
- Matches FPGA clock behavior (one value per clock cycle)
- HOLD body sees updated state between each pulse (critical for fibonacci)
- Maps directly to hardware synthesis mental model

### 2.4.10 Async Integration Boundary (Server)

EventLoop is sync internally; async lives at boundary:

```rust
impl EventLoop {
    pub fn handle_network_event(&mut self, event: NetworkEvent) {
        match event {
            NetworkEvent::MessageReceived(msg) => {
                self.enqueue_external_message(msg);
            }
            NetworkEvent::ConnectionClosed(session) => {
                self.schedule_session_cleanup(session);
            }
        }
    }

    pub fn drain_network_effects(&mut self) -> Vec<NetworkEffect> {
        std::mem::take(&mut self.pending_network_effects)
    }
}

// Async wrapper (runs in tokio/async-std)
pub async fn run_server_event_loop(mut event_loop: EventLoop, mut network: NetworkAdapter) {
    loop {
        tokio::select! {
            event = network.recv() => {
                event_loop.handle_network_event(event);
                event_loop.run_tick();

                for effect in event_loop.drain_network_effects() {
                    network.send(effect).await;
                }
            }
            _ = tokio::time::sleep(TICK_INTERVAL) => {
                event_loop.run_tick();
            }
        }
    }
}
```

### 2.4.11 Timer in Backgrounded Tabs

Browser throttles timers when tab is backgrounded:
- `requestAnimationFrame`: Stops completely
- `setTimeout`: Throttled to 1 call/second minimum

**Timer strategy with optional catch-up:**

```rust
pub struct TimerConfig {
    pub max_catchup_ticks: u32,  // 0 = no catchup, 10 = max 10 missed ticks
}

impl EventLoop {
    fn process_timers_with_catchup(&mut self, config: &TimerConfig) {
        let now = performance_now();
        while let Some(event) = self.timer_queue.peek() {
            if event.deadline_ms <= now {
                let event = self.timer_queue.pop().unwrap();
                self.mark_dirty(event.node_id);

                if let Some(interval_ms) = self.get_interval(event.node_id) {
                    let mut next_deadline = event.deadline_ms + interval_ms;
                    let mut catchup_count = 0;

                    // Optional catch-up for missed ticks
                    while next_deadline <= now && catchup_count < config.max_catchup_ticks {
                        self.mark_dirty(event.node_id);
                        next_deadline += interval_ms;
                        catchup_count += 1;
                    }
                    self.schedule_timer_at(event.node_id, next_deadline);
                }
            } else {
                break;
            }
        }
    }
}
```

**Defaults:**
- Animations: `max_catchup_ticks = 0` (just resume from current state)
- Counters/progress: `max_catchup_ticks = 100` (limited catch-up)

**Browser integration:** See §2.4.12 for microtask-based scheduling.

### 2.4.12 Microtask-Based Event Loop (Browser)

**Key insight:** Reactive propagation should use microtasks, not RAF or setTimeout.

| API | Timing | Use Case |
|-----|--------|----------|
| `queueMicrotask()` | After current task, before rendering | **Reactive propagation** |
| `requestAnimationFrame` | Before next repaint (~16ms) | Animation coordination |
| `setTimeout(fn, 0)` | Next event loop turn (4ms+ delay) | Timer scheduling |

**Why microtasks for propagation:**
- **No delay** - setTimeout has minimum 4ms, RAF waits for frame
- **Batching** - Multiple reactive updates complete before repaint
- **Consistency** - Same behavior whether triggered by sync or async code

**Architecture:**

```
┌─────────────────────────────────────────────────────────────┐
│  1. Event Source (DOM event, timer fire, network response) │
└─────────────────────────────────────────────────────────────┘
                              ↓
                     mark_dirty(node_id)
                              ↓
              queueMicrotask(|| run_tick())  ← schedules propagation
                              ↓
┌─────────────────────────────────────────────────────────────┐
│  2. Microtask: run_tick() until quiescence                  │
│     - Process all dirty nodes                               │
│     - Collect DOM updates                                   │
│     - Execute effects                                       │
└─────────────────────────────────────────────────────────────┘
                              ↓
                    Browser renders on next paint
```

**Implementation (inspired by MoonZoon Task::next_micro_tick):**

```rust
// Direct queueMicrotask binding
#[wasm_bindgen]
extern "C" {
    #[wasm_bindgen(js_name = queueMicrotask)]
    fn queue_microtask(callback: &js_sys::Function);
}

impl EventLoop {
    /// Schedule propagation as microtask (runs before next render)
    pub fn schedule_tick(&self) {
        if self.tick_scheduled.swap(true, Ordering::SeqCst) {
            return;  // Already scheduled
        }

        let event_loop = self.clone();  // Rc or similar
        let closure = Closure::once(move || {
            event_loop.tick_scheduled.store(false, Ordering::SeqCst);
            event_loop.run_tick();
        });

        queue_microtask(closure.as_ref().unchecked_ref());
        closure.forget();  // Or store handle to prevent drop
    }

    /// Called when any event marks a node dirty
    pub fn mark_dirty(&mut self, node: SlotId) {
        self.dirty_nodes.push(node);
        self.schedule_tick();  // Ensure propagation will run
    }
}
```

**`tick_scheduled` invariant (browser):**
- **Set to true:** BEFORE calling `queueMicrotask` (via `swap(true, ...)`)
- **Reset to false:** At START of callback, BEFORE `run_tick()` executes
- **Why reset early:** Events during `run_tick()` should schedule another tick. If reset at END, late events would be lost.

**CLI reentrancy guard (separate from tick_scheduled):**
CLI runs `schedule_microtask` callbacks synchronously, which could cause nested `run_tick()`. The solution uses an `in_tick` flag:

```rust
pub struct EventLoop {
    tick_scheduled: AtomicBool,   // "A microtask callback is queued"
    in_tick: AtomicBool,          // Reentrancy guard for CLI
    pending_ticks: AtomicU32,     // Count of deferred tick requests
    // ...
}

impl EventLoop {
    fn run_tick(&mut self) {
        // NOTE: tick_scheduled is reset in the callback, NOT here
        self.in_tick.store(true, Ordering::SeqCst);

        // Process dirty nodes, timers, etc.
        while !self.dirty_nodes.is_empty() { /* ... */ }

        self.in_tick.store(false, Ordering::SeqCst);

        // Check if we need another tick (events arrived during this one)
        if self.pending_ticks.swap(0, Ordering::SeqCst) > 0 {
            self.schedule_tick();
        }
    }

    fn schedule_tick(&self) {
        // CLI: If already in a tick, just count the request (don't touch tick_scheduled)
        if self.in_tick.load(Ordering::SeqCst) {
            self.pending_ticks.fetch_add(1, Ordering::SeqCst);
            return;
        }

        // Check if already scheduled (only after in_tick check)
        if self.tick_scheduled.swap(true, Ordering::SeqCst) {
            return;  // Already scheduled
        }

        self.platform.timer.schedule_microtask(Box::new(move || {
            // Reset tick_scheduled HERE (inside callback, before run_tick)
            self.tick_scheduled.store(false, Ordering::SeqCst);
            self.run_tick();
        }));
    }
}
```

**Key invariants:**
- `tick_scheduled` means "a microtask callback is queued" - reset inside callback, not in `run_tick()`
- `in_tick` is true ONLY during `run_tick()` execution
- When `in_tick` is true, `schedule_tick()` ONLY increments `pending_ticks` (does NOT touch `tick_scheduled`)
- At END of `run_tick()`, check `pending_ticks` and schedule another if needed
- This prevents nested calls while ensuring no events are lost

**Why this order matters:**
1. Check `in_tick` FIRST - if true, defer and return without touching `tick_scheduled`
2. Check `tick_scheduled` SECOND - if true, no need to queue another callback
3. Reset `tick_scheduled` in callback BEFORE `run_tick()` - events during tick can schedule new callback

**Timer scheduling still uses setTimeout:**
```rust
impl EventLoop {
    pub fn schedule_timer(&mut self, node: SlotId, delay_ms: u32) {
        let event_loop = self.clone();
        set_timeout(
            move || {
                event_loop.mark_dirty(node);  // This schedules microtask
            },
            delay_ms,
        );
    }
}
```

**Execution order example:**
```javascript
console.log('1. sync');
button.click();  // → mark_dirty → queueMicrotask(run_tick)
console.log('2. sync end');
// Microtask: run_tick() executes here
// → '3. propagation complete'
// Browser renders
```

**Benefits:**
- Reactive updates complete before browser paints (no flicker)
- Multiple events in same task batch into single propagation
- No artificial delays from setTimeout/RAF

**Files to modify:**
- `crates/boon/src/engine_v2/event_loop.rs` - EventLoop, timer queue, tick processing
- `crates/boon/src/evaluator_v2/api.rs` - Timer/interval using EventLoop
- `crates/boon/src/platform/browser/engine_v2_adapter.rs` - Microtask integration

---

