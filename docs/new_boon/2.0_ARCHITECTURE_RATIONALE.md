## Chapter 2.0: Architecture Rationale

This chapter explains **why** the new engine uses a synchronous event loop instead of async/await, and why this design is faster, simpler, and more deterministic than the old actor-based engine.

---

### 2.0.1 The Problem with the Old Engine

The current Boon engine uses async actors with `Arc<ValueActor>`, channels, and `spawn_local`. This causes several problems documented in CLAUDE.md:

**1. "Receiver is gone" errors:**
```rust
// Old engine: actor dropped while subscribers still active
let actor = ValueActor::new(...);
actor.subscribe()  // Works
// actor dropped here
subscriber.next().await  // ERROR: "receiver is gone"
```

**2. Debugging nightmare:**
```rust
// State scattered across:
// - Multiple spawned tasks
// - Channel buffers
// - Arc references
// - Async state machines
// Where is the bug? Good luck finding it.
```

**3. Cannot serialize/snapshot:**
```rust
// Futures contain closures, wakers, internal state
// IMPOSSIBLE to serialize for hot reload or persistence
let future = async { stream.next().await };
serde_json::to_string(&future)?;  // ERROR: not serializable
```

**4. Non-deterministic execution:**
```rust
// Which task runs first? Depends on executor, timing, moon phase...
spawn_local(task_a);
spawn_local(task_b);
// Result: non-reproducible bugs, flaky tests
```

**5. Reference counting overhead:**
```rust
// Every value wrapped in Arc
// Every access: atomic increment/decrement
// Every clone: cache line bouncing
Arc<ValueActor<Arc<Value>>>  // Arcs all the way down
```

---

### 2.0.2 The Solution: Synchronous Event Loop

The new engine replaces async actors with a **synchronous tick-based event loop**:

```rust
pub struct EventLoop {
    arena: Arena,                      // All nodes in contiguous memory
    dirty_nodes: Vec<SlotId>,          // Nodes needing update
    pending_effects: Vec<NodeEffect>,  // FIFO effect queue
    current_tick: u64,
}

impl EventLoop {
    /// Single synchronous tick - no async, no await
    pub fn run_tick(&mut self) {
        self.current_tick += 1;

        // 1. Process external inputs
        self.process_timers();
        self.process_dom_events();

        // 2. Propagate until quiescence (no more dirty nodes)
        while !self.dirty_nodes.is_empty() {
            self.dirty_nodes.sort_by_key(|n| /* deterministic order */);
            for node in self.dirty_nodes.drain(..) {
                let new_dirty = self.process_node(node);
                self.dirty_nodes.extend(new_dirty);
            }
        }

        // 3. Execute effects in FIFO order
        for effect in self.pending_effects.drain(..) {
            self.execute_effect(effect);
        }
    }
}
```

**This is just a while loop.** No tasks, no wakers, no poll state machines.

---

### 2.0.3 Why Synchronous is Faster

| Operation | Async/Futures | Sync Event Loop |
|-----------|---------------|-----------------|
| **Task creation** | Allocate Future, Box it, store in queue | Nothing - just mark dirty |
| **Context switch** | Save/restore state machine, waker dance | Direct function call |
| **Value access** | Arc::clone, atomic ops | Direct arena index |
| **Memory layout** | Scattered heap allocations | Contiguous arena |
| **Cache behavior** | Pointer chasing, cache misses | Linear iteration, prefetch-friendly |

**Async executor overhead visualized:**

```
spawn_local(future)
    ↓
┌─────────────────────────────────────────┐
│ 1. Box the Future (heap allocation)      │
│ 2. Create Waker (another allocation)     │
│ 3. Push to task queue                    │
│ 4. Executor polls task                   │
│ 5. Future returns Poll::Pending          │
│ 6. Store state machine state             │
│ 7. ... wait for waker ...                │
│ 8. Waker fires, re-queue task            │
│ 9. Executor polls again                  │
│ 10. Repeat until Poll::Ready             │
└─────────────────────────────────────────┘
```

**Synchronous event loop:**

```
mark_dirty(node)
    ↓
┌─────────────────────────────────────────┐
│ 1. Push SlotId to Vec (1 usize)          │
│ 2. queueMicrotask(run_tick) if needed    │
│ ... microtask runs ...                   │
│ 3. while loop processes all dirty nodes  │
│ 4. Done                                  │
└─────────────────────────────────────────┘
```

**Benchmark expectation:** 10-100x fewer allocations, 2-10x faster propagation.

---

### 2.0.4 Why Synchronous is More Deterministic

**Problem with async:** Execution order depends on executor implementation, system load, and timing.

```rust
// Async: race condition
spawn_local(async { value_a.set(1) });
spawn_local(async { value_b.set(value_a.get()) });
// value_b could be 0 or 1 depending on scheduling
```

**Synchronous solution:** Explicit ordering guarantees.

```rust
// Sync: deterministic
// Nodes processed in sorted order: (source_id, scope_id, port)
while !dirty_nodes.is_empty() {
    dirty_nodes.sort_by_key(|n| (n.source_id, n.scope_id));
    // Same input ALWAYS produces same output
}
```

**Determinism enables:**
- **Replay debugging** - Record inputs, replay exact execution
- **Distributed consistency** - Same state on client and server
- **Test reproducibility** - No flaky tests from timing
- **Time-travel debugging** - Step forward/backward through ticks

---

### 2.0.5 Why FIFO Effect Ordering

Effects (console.log, navigation, localStorage) execute at tick end. Order matters:

```boon
button |> LINK { click } |> THEN {
    Console/log("Starting checkout")
    Analytics/track("checkout_started")
    Router/go_to("/checkout")
}
```

**FIFO guarantees:** log → track → navigate (matches code order)

**"Unspecified" would mean:** Maybe navigate → log → track? Confusing!

**Performance comparison:**

| Approach | Insert | Execute | Memory | Cache |
|----------|--------|---------|--------|-------|
| **FIFO (Vec)** | O(1) push | O(n) drain | Contiguous | Excellent |
| Priority (BinaryHeap) | O(log n) | O(n log n) | Tree nodes | Poor |
| Unspecified (HashMap) | O(1) amortized | O(n) random | Buckets | Poor |

**FIFO is both simplest and fastest.** There's no trade-off.

```rust
impl EventLoop {
    pending_effects: Vec<NodeEffect>,  // Simple Vec

    fn queue_effect(&mut self, effect: NodeEffect) {
        self.pending_effects.push(effect);  // O(1)
    }

    fn execute_pending_effects(&mut self) {
        for effect in self.pending_effects.drain(..) {  // Linear, in order
            self.execute_effect(effect);
        }
    }
}
```

---

### 2.0.6 Why Microtasks (Not RAF or setTimeout)

The event loop is synchronous internally, but needs browser integration:

| API | When it runs | Delay | Use for |
|-----|--------------|-------|---------|
| `queueMicrotask()` | After current JS, before render | ~0ms | **Reactive propagation** |
| `requestAnimationFrame` | Before next paint | ~16ms | Animation sync |
| `setTimeout(fn, 0)` | Next event loop turn | 4ms+ | Timer scheduling |

**Why microtasks for propagation:**

```javascript
// User clicks button
button.onclick = () => {
    mark_dirty(some_node);
    // queueMicrotask(run_tick) scheduled here
};
console.log("handler done");

// Microtask runs HERE - before browser renders
// All reactive updates complete
// Then browser paints - no flicker!
```

**With setTimeout:**
```javascript
button.onclick = () => {
    mark_dirty(some_node);
    setTimeout(run_tick, 0);  // 4ms+ delay!
};
// Browser might render BEFORE run_tick
// User sees stale state - flicker!
```

---

### 2.0.7 Comparison: Old Engine vs New Engine

| Aspect | Old Engine (Async Actors) | New Engine (Sync Event Loop) |
|--------|---------------------------|------------------------------|
| **State location** | Scattered across tasks, channels, Arcs | Single arena, contiguous memory |
| **Debugging** | "Receiver is gone" - where? | Dump arena, see everything |
| **Serialization** | Impossible (closures, wakers) | Trivial (plain data) |
| **Determinism** | Executor-dependent | Explicit sort order |
| **Memory** | Arc overhead, heap fragmentation | Arena allocation, cache-friendly |
| **Hot reload** | Cannot preserve state | Full state preservation |
| **FPGA target** | No mapping | Direct synthesis (tick = clock) |

---

### 2.0.8 The Hardware Mental Model

The synchronous event loop maps naturally to hardware:

```
Software (Event Loop)          Hardware (FPGA)
─────────────────────          ───────────────
Tick                      →    Clock cycle
Node                      →    Register + combinational logic
Dirty propagation         →    Signal propagation
Quiescence               →    Stable state before next clock edge
FIFO effect queue        →    Output buffer
```

This isn't just an analogy - it's the path to FPGA synthesis (Phase 14). The same Boon code can run in browser (event loop) or hardware (clock cycles).

---

### 2.0.9 Where Async IS Appropriate

Async belongs at the **boundary**, not in the reactive core:

```rust
// BOUNDARY: Server network layer (async)
pub async fn run_server(mut event_loop: EventLoop, network: NetworkAdapter) {
    loop {
        tokio::select! {
            msg = network.recv() => {
                event_loop.handle_message(msg);  // Sync!
                event_loop.run_tick();           // Sync!
            }
            _ = tokio::time::sleep(TICK_INTERVAL) => {
                event_loop.run_tick();           // Sync!
            }
        }
    }
}

// BOUNDARY: Browser timer (async via JS)
set_timeout(|| {
    event_loop.mark_dirty(timer_node);  // Sync!
    // queueMicrotask handles propagation
}, delay_ms);

// CORE: Pure synchronous propagation
impl EventLoop {
    pub fn run_tick(&mut self) {  // NOT async!
        while !self.dirty_nodes.is_empty() {
            // Pure synchronous loop
        }
    }
}
```

**Pattern:** Async adapters feed events into sync core, sync core produces effects, async adapters execute effects.

---

### 2.0.10 Summary

| Decision | Rationale |
|----------|-----------|
| **Sync event loop** | Faster, debuggable, serializable, deterministic |
| **Arena allocation** | Cache-friendly, snapshot-able, no Arc overhead |
| **FIFO effects** | Deterministic, intuitive, fastest implementation |
| **Microtask scheduling** | Immediate propagation, no flicker, batched updates |
| **Async at boundary** | Best of both worlds - async I/O, sync reactive core |

The new architecture solves the fundamental problems of the old engine while being simpler, faster, and enabling new capabilities (hot reload, FPGA synthesis, time-travel debugging).

---

